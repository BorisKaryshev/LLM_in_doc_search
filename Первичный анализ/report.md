## ТЗ
Стояла задача подключить LLM через API и попробовать использовать её для поиска информации по тексту

    На вход подаётся даташит и пользовательский запрос.


## Что делал
Удалось подключить только GigaCHAT, т. к. ChatGPT и YandexGPT платные.

Попробовал подать простенький даташит в виде таблицы и в виде текста. 

    Вроде как LLM лучше воспринимает таблицу.

На вопросы чаще всего отвечает правильно, но не всегда.


## Вывод
Мой вариант архитектуры выглядит как-то так:

    Пользователь -> LLM -> "Поисковик" -> LLM -> Пользователь

    Пользователь подаёт запрос в свободной форме к LLM, она генерит запрос к поисковику, он подбирает нужный компонент и возвращает данные LLM, которая генерит ответ пользователю
    
    Над поисковиком надо подумать. Моих текущих знаний явно не достаточно для его реализации. 
    Мб для подбора простых компонентов (кондёры, транзисторы, операционники) имеет смысл использовать не ML, а что-то из методов оптимизации.


## Из того что нагуглил

Можно реализовать RAG (подмешиваем данные из поисковика к запросу в LLM)

    Выше я предложил по сути её, но для поиска формирования запроса к "поисковику" используется LLM.

    Я не уверен, что эмбеддинги будут всегда хорошо работать.

    Например если стоит задача подобрать оптимальный транзистор по нескольким параметрам, то релевантная разница между даташитами будет в нескольких числах, что эмбеддинг может не учесть.
      
Статья на хабре про похожий проект:
    
    https://habr.com/ru/articles/778170/
